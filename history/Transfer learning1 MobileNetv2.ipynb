{
  "cells": [
    {
      "metadata": {
        "id": "8f50a9f66adbfc04"
      },
      "cell_type": "markdown",
      "source": [
        "# Image classification with transfer learning"
      ],
      "id": "8f50a9f66adbfc04"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Pre-processing**"
      ],
      "metadata": {
        "id": "aqK8Ze-jXYKr"
      },
      "id": "aqK8Ze-jXYKr"
    },
    {
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53ded9d92832209a",
        "outputId": "f19a78b2-913b-4f1f-c7b3-43a2a3e6e4e7",
        "ExecuteTime": {
          "end_time": "2025-10-23T18:34:21.469130Z",
          "start_time": "2025-10-23T18:34:21.445128Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#Importing dataset from CIFAR\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Load CIFAR-10 dataset and print shapes\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "id": "53ded9d92832209a",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "y_test shape: (10000, 1)\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-processing classes (y)**"
      ],
      "metadata": {
        "id": "M76nrQzctX1Z"
      },
      "id": "M76nrQzctX1Z"
    },
    {
      "metadata": {
        "id": "3d56960e9ba3f5de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea42d2b-0d5e-43f8-e02a-c862d793790a"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train_cat shape: (50000, 10)\n",
            "y_test_cat shape: (10000, 10)\n"
          ]
        }
      ],
      "execution_count": 2,
      "source": [
        "# convert classes into categories with one hot encoding and check shape.\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"y_train_cat shape:\", y_train.shape)\n",
        "print(\"y_test_cat shape:\", y_test.shape)"
      ],
      "id": "3d56960e9ba3f5de"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-processing images**\n",
        "\n",
        "to make them compatible with the shapes and scales in our base model (MobileNetV2)\n"
      ],
      "metadata": {
        "id": "gnZmQVTNmau2"
      },
      "id": "gnZmQVTNmau2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping image to be compatible with base model. In batches, to avoid crashing.\n",
        "\n",
        "def resize_in_batches_cpu(images, new_size=(160, 160), batch_size=1000):\n",
        "    resized_batches = []\n",
        "    with tf.device('/CPU:0'):  # force CPU to avoid GPU OOM\n",
        "        for i in range(0, len(images), batch_size):\n",
        "            batch = images[i:i+batch_size]\n",
        "            batch_resized = tf.image.resize(batch, new_size).numpy()\n",
        "            resized_batches.append(batch_resized)\n",
        "    return np.concatenate(resized_batches, axis=0)\n",
        "\n",
        "x_train_resized = resize_in_batches_cpu(x_train)\n",
        "x_test_resized = resize_in_batches_cpu(x_test)\n",
        "\n",
        "print(\"Resized shapes:\", x_train_resized.shape, x_test_resized.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22V35VZo-wPz",
        "outputId": "56b30e5e-69d9-4cfd-9730-c9d2a808c441"
      },
      "id": "22V35VZo-wPz",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resized shapes: (50000, 160, 160, 3) (10000, 160, 160, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Keras function is specifically designed to make images compatible with the MobileNetV2 model.\n",
        "# It involves scaling and shifting pixel values to [-1, 1], as the model was trained on.\n",
        "\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "# Preprocess your data\n",
        "x_train = preprocess_input(x_train_resized)\n",
        "x_test = preprocess_input(x_test_resized)\n"
      ],
      "metadata": {
        "id": "XBNLm_5YmZQ3"
      },
      "id": "XBNLm_5YmZQ3",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "185fd38539db54fb"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Since we are using a Transfer learning technique, we need to merge features and labels into datasets, so that they can be processed correctly at a later stage.\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "id": "185fd38539db54fb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the base model from the pre-trained convnets"
      ],
      "metadata": {
        "id": "8Fd0_7vmatdm"
      },
      "id": "8Fd0_7vmatdm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = (160,160,3)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "\n",
        "\n",
        "#Freeze the convolutional base to prevent the weights from being updated during training.\n",
        "base_model.trainable = False\n",
        "\n"
      ],
      "metadata": {
        "id": "6CwgEINaan6b"
      },
      "id": "6CwgEINaan6b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building and training transfer learning model"
      ],
      "metadata": {
        "id": "lK2FC_33xO6E"
      },
      "id": "lK2FC_33xO6E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply Global Average Pooling**\n",
        "to convert feature maps (from base model) to vectors"
      ],
      "metadata": {
        "id": "mYJ23HcHzrFw"
      },
      "id": "mYJ23HcHzrFw"
    },
    {
      "cell_type": "code",
      "source": [
        "# First we need to create batched datasets. We will make this as an isolated variable so that we can tweak it to fine-tune the model if needed.\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n"
      ],
      "metadata": {
        "id": "yyAdQfAzz3E2"
      },
      "id": "yyAdQfAzz3E2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add a classification head**"
      ],
      "metadata": {
        "id": "UT8ojc8izjAB"
      },
      "id": "UT8ojc8izjAB"
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch, label_batch = next(iter(train_dataset))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)\n",
        "\n",
        "# Apply Global Average Pooling to convert feature maps to vectors\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(f\"Feature batch average shape: {feature_batch_average.shape}\")\n",
        "\n",
        "\n",
        "# Classification head: In our case, it will be 10 neurons dense since this is the number of categories.\n",
        "# Using Softmax as the activation function since this is the ideal choice for classification problems.\n",
        "prediction_layer = tf.keras.layers.Dense(10, activation='softmax')\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(f\"Prediction batch shape: {prediction_batch.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "klCher4ZpKij"
      },
      "id": "klCher4ZpKij",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now to the model**"
      ],
      "metadata": {
        "id": "K_MhnmBd3Sqd"
      },
      "id": "K_MhnmBd3Sqd"
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "N6cW0OpO3cUS"
      },
      "id": "N6cW0OpO3cUS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "len(model.trainable_variables)\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "wcgPklhHzinj"
      },
      "id": "wcgPklhHzinj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile and fit the model"
      ],
      "metadata": {
        "id": "vdRjsoYX7fij"
      },
      "id": "vdRjsoYX7fij"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # Using one-hot encoded labels\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "# Step 5: Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=test_dataset\n",
        ")\n",
        "\n",
        "# Step 6: Evaluate on test set\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"\\nTest accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Step 7: Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "50omyX0CyMpJ"
      },
      "id": "50omyX0CyMpJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6548f999e5006af2"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "##block of code used to clear keras sessions during development\n",
        "\n",
        "from keras.backend import clear_session\n",
        "clear_session()"
      ],
      "id": "6548f999e5006af2"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CfkkmyMAr0sm"
      },
      "id": "CfkkmyMAr0sm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}